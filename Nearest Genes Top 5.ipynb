{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c90236e5",
   "metadata": {},
   "source": [
    "# Import Gene Annotation File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d879e7c",
   "metadata": {},
   "source": [
    "https://github.com/hakha-most/gwas_eqtl/blob/master/gene_annotations/genes.protein_coding.v39.gtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e64af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "\n",
    "# Local path to GTF file\n",
    "gtf_file_path = '/Users/oliverkafka/Documents/NYU/3rd Sem NYU/Captone Project/Data/genes.protein_coding.v39.gtf'\n",
    "# Path to GWAS file\n",
    "gwas_file_path = '/Users/oliverkafka/Documents/NYU/3rd Sem NYU/Captone Project/Data/50_irnt.gwas.imputed_v3.both_sexes.tsv.bgz'\n",
    "# Path to S Het file\n",
    "s_het_file_path = '/Users/oliverkafka/Documents/NYU/3rd Sem NYU/Captone Project/Data/s_het_info.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd76a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GTF file into a pandas DataFrame and use the first row as headers\n",
    "gtf_df = pd.read_csv(gtf_file_path, sep='\\t', header=0)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "gtf_df.sort_values('start')\n",
    "gtf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94594772",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0675ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf_df['chr'] = gtf_df['chr'].str[3:].astype(int)\n",
    "gtf_df['start'] = gtf_df['start'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeda7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf_df.groupby('chr')['start'].agg({'min', 'max'}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b213fee",
   "metadata": {},
   "source": [
    "Positions reset for each chromosome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56838c6",
   "metadata": {},
   "source": [
    "### File Description\n",
    "\n",
    "This file contains **gene annotations** for **protein-coding genes** and provides information about the **location of genes on the genome**. Below is a description of each column:\n",
    "\n",
    "1. **chr**: The chromosome where the gene is located (e.g., `chr1`, `chr2`, etc.).\n",
    "2. **start**: The start position of the gene on the chromosome (in base pairs).\n",
    "3. **end**: The end position of the gene on the chromosome (in base pairs).\n",
    "4. **strand**: Indicates the strand on which the gene is located (`+` for forward strand, `-` for reverse strand).\n",
    "5. **GeneSymbol**: The symbol or name of the gene (e.g., `OR4F5`, `SAMD11`), typically assigned by organizations like HGNC (HUGO Gene Nomenclature Committee).\n",
    "6. **cons**: This column indicates the type of gene. In this file, all genes are classified as **protein_coding**.\n",
    "7. **gene**: The Ensembl gene ID, a unique identifier for the gene (e.g., `ENSG00000186092`).\n",
    "8. **hgnc_id**: The unique identifier for the gene assigned by the **HGNC** (HUGO Gene Nomenclature Committee).\n",
    "9. **tss**: The **transcription start site**, the position where transcription of the gene starts on the chromosome.\n",
    "10. **tes**: The **transcription end site**, the position where transcription of the gene ends on the chromosome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b718549",
   "metadata": {},
   "source": [
    "# Import GWAS data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b3f6e1",
   "metadata": {},
   "source": [
    " https://docs.google.com/spreadsheets/d/1kvPoupSzsSFBNSztMzl04xMoSC3Kcx3CrjVf4yBmESU/edit?gid=178908679#gid=178908679 (row 7217)\n",
    " \n",
    " 50_irnt.gwas.imputed_v3.both_sexes.tsv.bgz' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403cfbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the compressed .bgz file using gzip\n",
    "with gzip.open(gwas_file_path, 'rt') as f:\n",
    "    # Load the file into a pandas DataFrame\n",
    "    gwas_df = pd.read_csv(f, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba1882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows to inspect the structure of the GWAS file\n",
    "gwas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dcbac5",
   "metadata": {},
   "source": [
    "### GWAS Summary Statistics Dataset Description\n",
    "\n",
    "1. **variant**: The unique identifier for each SNP (Single Nucleotide Polymorphism). This can include information like chromosome, position, reference allele, and alternative allele (e.g., `1:12345:A:G`).\n",
    "   - **Example**: `1:10583:T:G`\n",
    "\n",
    "2. **minor_allele**: The allele that is less frequent in the population (minor allele) for this particular SNP.\n",
    "   - **Example**: `G`\n",
    "\n",
    "3. **minor_AF**: The **minor allele frequency** (AF), which represents the frequency of the minor allele in the population. It ranges from 0 to 1.\n",
    "   - **Example**: `0.35` (35% of individuals carry the minor allele)\n",
    "\n",
    "4. **low_confidence_variant**: A flag indicating whether the variant has **low confidence** due to imputation quality or other uncertainties. Values may be `TRUE` or `FALSE`.\n",
    "   - **Example**: `FALSE`\n",
    "\n",
    "5. **n_complete_samples**: The number of samples for which complete genotype data is available for this variant.\n",
    "   - **Example**: `300,000`\n",
    "\n",
    "6. **AC**: The **allele count** of the minor allele, i.e., the number of times the minor allele appears in the study population (across all samples).\n",
    "   - **Example**: `50000`\n",
    "\n",
    "7. **ytx**: Likely a placeholder for a phenotype-related statistic; depending on the dataset, this could represent something like the trait mean or effect size (its exact meaning depends on the specific analysis).\n",
    "\n",
    "8. **beta**: The **effect size** of the SNP on the trait being studied (in this case, likely height). It represents the change in the trait per additional copy of the minor allele.\n",
    "   - **Example**: `0.05` (the trait increases by 0.05 units for each additional copy of the minor allele)\n",
    "\n",
    "9. **se**: The **standard error** of the effect size (beta), indicating the precision of the estimated effect.\n",
    "   - **Example**: `0.01`\n",
    "\n",
    "10. **tstat**: The **t-statistic** for the beta estimate, which is the ratio of the beta estimate to its standard error.\n",
    "    - **Example**: `5.0` (higher values indicate more significant associations)\n",
    "\n",
    "11. **pval**: The **p-value** of the association between the SNP and the trait. This indicates the significance of the result, with smaller p-values suggesting stronger evidence that the SNP is associated with the trait.\n",
    "    - **Example**: `1.2e-6` (a very small p-value, indicating strong evidence of association)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8057166",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae761ce1",
   "metadata": {},
   "source": [
    "# Find Variant Chromosome and Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ce043",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas_df[['chr', 'pos', 'ref', 'alt']] = gwas_df['variant'].str.split(':', expand=True)\n",
    "gwas_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53555b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas_df = gwas_df[gwas_df['chr'] != 'X']\n",
    "gwas_df['chr'] = gwas_df['chr'].astype(int)\n",
    "gwas_df['pos'] = gwas_df['pos'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d948d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas_df.groupby('chr')['pos'].agg({'min','max'}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef1311b",
   "metadata": {},
   "source": [
    "It appears that position resets on each chromosome "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7446d01",
   "metadata": {},
   "source": [
    "# Join to Find 5 Nearest Genes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52752a39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def repeated_forward_merge(gwas_df, gtf_df, num_merges=3):\n",
    "    # Initial sorting of key columns for the first merge\n",
    "    gwas_sorted = gwas_df[['variant', 'pval', 'chr', 'pos']].sort_values('pos')\n",
    "    gtf_sorted = gtf_df[['chr', 'start', 'GeneSymbol', 'gene']].sort_values('start')\n",
    "\n",
    "    # Ensure both 'start' columns are of the same type (convert to float to handle NaNs)\n",
    "    gtf_sorted['start'] = gtf_sorted['start'].astype(float)\n",
    "    gwas_sorted['pos'] = gwas_sorted['pos'].astype(float)\n",
    "\n",
    "    # First merge_asof\n",
    "    merged_df = pd.merge_asof(\n",
    "        gwas_sorted, \n",
    "        gtf_sorted, \n",
    "        by='chr', \n",
    "        left_on='pos', \n",
    "        right_on='start', \n",
    "        direction='forward',\n",
    "        suffixes=('', '_f1')  # First set of suffixes\n",
    "    )\n",
    "\n",
    "    # Replace NaN values in 'start' column and rename for subsequent merges\n",
    "    merged_df['start'] = merged_df['start'].fillna(np.inf)\n",
    "    merged_df = merged_df.rename(columns={'start': 'start_f1', 'GeneSymbol': 'GeneSymbol_f1', 'gene': 'gene_f1'})\n",
    "    merged_df = merged_df.sort_values('start_f1')\n",
    "\n",
    "    # Iterative forward merges\n",
    "    for i in range(2, num_merges + 1):\n",
    "        # Ensure both columns are of the same type\n",
    "        merged_df[f'start_f{i-1}'] = merged_df[f'start_f{i-1}'].astype(float)\n",
    "        gtf_sorted['start'] = gtf_sorted['start'].astype(float)\n",
    "\n",
    "        # Perform the next forward merge\n",
    "        merged_df = pd.merge_asof(\n",
    "            merged_df, \n",
    "            gtf_sorted, \n",
    "            by='chr', \n",
    "            left_on=f'start_f{i-1}', \n",
    "            right_on='start', \n",
    "            direction='forward',\n",
    "            allow_exact_matches=False,\n",
    "            suffixes=(f'_f{i-1}', f'_f{i}')\n",
    "        )\n",
    "\n",
    "        # Replace NaN values in the new 'start' column and rename for next iteration\n",
    "        merged_df['start'] = merged_df['start'].fillna(np.inf)\n",
    "        merged_df = merged_df.rename(columns={\n",
    "            'start': f'start_f{i}', \n",
    "            'GeneSymbol': f'GeneSymbol_f{i}', \n",
    "            'gene': f'gene_f{i}'\n",
    "        })\n",
    "        merged_df = merged_df.sort_values(f'start_f{i}')\n",
    "\n",
    "    # After the last merge, replace all np.inf values back to NaN\n",
    "    for i in range(1, num_merges + 1):\n",
    "        merged_df[f'start_f{i}'] = merged_df[f'start_f{i}'].replace(np.inf, np.nan)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "f_final = repeated_forward_merge(gwas_df, gtf_df, num_merges=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02652096",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0172e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted function to ensure all negative infinity values are replaced with NaN in the final result\n",
    "def repeated_backward_merge_with_nan(gwas_df, gtf_df, num_merges=3):\n",
    "    # Initial sorting of key columns for the first merge\n",
    "    gwas_sorted = gwas_df.sort_values('pos')\n",
    "    gtf_sorted = gtf_df[['chr', 'start', 'GeneSymbol', 'gene']].sort_values('start')\n",
    "\n",
    "    # Ensure both 'start' columns are of the same type (convert to float to handle NaNs)\n",
    "    gtf_sorted['start'] = gtf_sorted['start'].astype(float)\n",
    "    gwas_sorted['pos'] = gwas_sorted['pos'].astype(float)\n",
    "\n",
    "    # First backward merge_asof\n",
    "    merged_df = pd.merge_asof(\n",
    "        gwas_sorted, \n",
    "        gtf_sorted, \n",
    "        by='chr', \n",
    "        left_on='pos', \n",
    "        right_on='start', \n",
    "        direction='backward',\n",
    "        suffixes=('', '_b1')  # First set of suffixes\n",
    "    )\n",
    "\n",
    "    # Replace NaN values in 'start' column and rename for subsequent merges\n",
    "    merged_df['start'] = merged_df['start'].fillna(-np.inf)\n",
    "    merged_df = merged_df.rename(columns={'start': 'start_b1', 'GeneSymbol': 'GeneSymbol_b1', 'gene': 'gene_b1'})\n",
    "    merged_df = merged_df.sort_values('start_b1')\n",
    "\n",
    "    # Iterative backward merges\n",
    "    for i in range(2, num_merges + 1):\n",
    "        # Ensure both columns are of the same type\n",
    "        merged_df[f'start_b{i-1}'] = merged_df[f'start_b{i-1}'].astype(float)\n",
    "        gtf_sorted['start'] = gtf_sorted['start'].astype(float)\n",
    "\n",
    "        # Perform the next backward merge\n",
    "        merged_df = pd.merge_asof(\n",
    "            merged_df, \n",
    "            gtf_sorted, \n",
    "            by='chr', \n",
    "            left_on=f'start_b{i-1}', \n",
    "            right_on='start', \n",
    "            direction='backward',\n",
    "            allow_exact_matches=False,\n",
    "            suffixes=(f'_b{i-1}', f'_b{i}')\n",
    "        )\n",
    "\n",
    "        # Replace NaN values in the new 'start' column and rename for next iteration\n",
    "        merged_df['start'] = merged_df['start'].fillna(-np.inf)\n",
    "        merged_df = merged_df.rename(columns={\n",
    "            'start': f'start_b{i}', \n",
    "            'GeneSymbol': f'GeneSymbol_b{i}', \n",
    "            'gene': f'gene_b{i}'\n",
    "        })\n",
    "        merged_df = merged_df.sort_values(f'start_b{i}')\n",
    "\n",
    "    # After the last merge, replace all -np.inf values back to NaN\n",
    "    for i in range(1, num_merges + 1):\n",
    "        merged_df[f'start_b{i}'] = merged_df[f'start_b{i}'].replace(-np.inf, np.nan)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Example usage:\n",
    "f_b_final = repeated_backward_merge_with_nan(f_final, gtf_df, num_merges=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac3902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_b_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b0ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate differences between pos and all forward and backward start columns\n",
    "def calculate_differences(df, num_merges=3):\n",
    "    # Calculate the difference between pos and start_f1, start_f2, ..., start_fx for forward merges\n",
    "    for i in range(1, num_merges + 1):\n",
    "        df[f'diff_f{i}'] = df[f'start_f{i}'] - df['pos']\n",
    "    \n",
    "    # Calculate the difference between pos and start_b1, start_b2, ..., start_bx for backward merges\n",
    "    for i in range(1, num_merges + 1):\n",
    "        df[f'diff_b{i}'] = df[f'start_b{i}'] - df['pos']\n",
    "    \n",
    "    return df\n",
    "\n",
    "f_b_final_with_differences = calculate_differences(f_b_final, num_merges=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684de9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_b_final_with_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01084630",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_b_final_with_differences[['diff_f1', 'diff_f2', 'diff_f3', 'diff_b1', 'diff_b2', 'diff_b3']].tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e885c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_b_final_with_differences[['diff_f1', 'diff_f2', 'diff_f3', 'diff_b1', 'diff_b2', 'diff_b3']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc47c087",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot histograms for each difference column\n",
    "def plot_histograms(df, columns):\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    for i, col in enumerate(columns):\n",
    "        plt.subplot(2, 3, i + 1)  # Create a subplot for each column\n",
    "        df[col].hist(bins=50, color='skyblue', edgecolor='black')\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define the columns to plot\n",
    "columns_to_plot = ['diff_f1', 'diff_f2', 'diff_f3', 'diff_b1', 'diff_b2', 'diff_b3']\n",
    "\n",
    "# Call the function to plot histograms\n",
    "plot_histograms(f_b_final_with_differences, columns_to_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e196a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_het_info = pd.read_excel(s_het_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de16b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_het_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b4060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform the merge for all forward and backward GeneSymbols and rename the 'post_mean' columns\n",
    "def merge_s_het_info_with_all(f_b_final_with_differences, s_het_info, num_merges=3):\n",
    "    # Rename 'ensg' column in s_het_info to match the GeneSymbol columns in f_b_final_with_differences\n",
    "    s_het_info = s_het_info.rename(columns={'ensg': 'GeneSymbol'})\n",
    "\n",
    "    # Iterate over both forward and backward gene symbols\n",
    "    for i in range(1, num_merges + 1):\n",
    "        # Forward merge for each GeneSymbol_f\n",
    "        f_b_final_with_differences = pd.merge(\n",
    "            f_b_final_with_differences, \n",
    "            s_het_info[['GeneSymbol', 'post_mean']], \n",
    "            left_on=f'GeneSymbol_f{i}', \n",
    "            right_on='GeneSymbol', \n",
    "            how='left',\n",
    "            suffixes=('', f'_f{i}')\n",
    "        )\n",
    "        \n",
    "        # Rename the post_mean column to indicate the forward direction\n",
    "        f_b_final_with_differences = f_b_final_with_differences.rename(\n",
    "            columns={'post_mean': f's_het_post_f{i}'}\n",
    "        )\n",
    "        \n",
    "        # Drop the duplicated 'GeneSymbol' column created during the merge\n",
    "        f_b_final_with_differences = f_b_final_with_differences.drop(columns='GeneSymbol', errors='ignore')\n",
    "\n",
    "        # Backward merge for each GeneSymbol_b\n",
    "        f_b_final_with_differences = pd.merge(\n",
    "            f_b_final_with_differences, \n",
    "            s_het_info[['GeneSymbol', 'post_mean']], \n",
    "            left_on=f'GeneSymbol_b{i}', \n",
    "            right_on='GeneSymbol', \n",
    "            how='left',\n",
    "            suffixes=('', f'_b{i}')\n",
    "        )\n",
    "        \n",
    "        # Rename the post_mean column to indicate the backward direction\n",
    "        f_b_final_with_differences = f_b_final_with_differences.rename(\n",
    "            columns={'post_mean': f's_het_post_b{i}'}\n",
    "        )\n",
    "        \n",
    "        # Drop the duplicated 'GeneSymbol' column created during the merge\n",
    "        f_b_final_with_differences = f_b_final_with_differences.drop(columns='GeneSymbol', errors='ignore')\n",
    "\n",
    "    return f_b_final_with_differences\n",
    "\n",
    "# Example usage:\n",
    "f_b_final_merged_s_het = merge_s_het_info_with_all(f_b_final_with_differences, s_het_info, num_merges=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_b_final_merged_s_het.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d5d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_b_final_merged_s_het"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8643ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_abs_diff_b(f_b_final_merged_s_het, num_merges=3):\n",
    "    for i in range(1, num_merges + 1):\n",
    "        f_b_final_merged_s_het[f'diff_b{i}'] = f_b_final_merged_s_het[f'diff_b{i}'].abs()\n",
    "\n",
    "    return f_b_final_merged_s_het\n",
    "\n",
    "# Example usage:\n",
    "f_b_final_merged_s_het = apply_abs_diff_b(f_b_final_merged_s_het, num_merges=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a552cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_b_final_merged_s_het"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59827a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set distances where we overlap with start of gene to 1\n",
    "f_b_final_merged_s_het.loc[f_b_final_merged_s_het['start_f1'] == f_b_final_merged_s_het['pos'], 'diff_f1'] = 1\n",
    "f_b_final_merged_s_het.loc[f_b_final_merged_s_het['start_b1'] == f_b_final_merged_s_het['pos'], 'diff_b1'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b5e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to keep only the distance and s_het measures from the dataframe\n",
    "def keep_dist_and_s_het_measures(df, num_merges=3):\n",
    "    # List to store column names for distance and s_het measures\n",
    "    columns_to_keep = ['variant', 'chr', 'pos']\n",
    "\n",
    "    # Loop to collect the diff and s_het_post column names for forward and backward directions\n",
    "    for i in range(1, num_merges + 1):\n",
    "        columns_to_keep.append(f'diff_f{i}')\n",
    "        columns_to_keep.append(f'diff_b{i}')\n",
    "        columns_to_keep.append(f's_het_post_f{i}')\n",
    "        columns_to_keep.append(f's_het_post_b{i}')\n",
    "\n",
    "    # Keep only the relevant columns\n",
    "    df_filtered = df[columns_to_keep]\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "# Example usage:\n",
    "filtered_f_b_final = keep_dist_and_s_het_measures(f_b_final_merged_s_het, num_merges=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c059659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_f_b_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e014e775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute s_het weighted by 1/distance per gene-SNP pair\n",
    "def compute_weighted_s_het(df, num_merges=3):\n",
    "    # Loop to compute the weighted s_het for both forward and backward directions\n",
    "    for i in range(1, num_merges + 1):\n",
    "        # Calculate inverse distance for forward and backward directions\n",
    "        df[f'inv_dist_f{i}'] = 1 / df[f'diff_f{i}']\n",
    "        df[f'inv_dist_b{i}'] = 1 / df[f'diff_b{i}']\n",
    "        \n",
    "        # Compute weighted s_het by multiplying s_het by inverse distance\n",
    "        df[f'weighted_s_het_f{i}'] = df[f'inv_dist_f{i}'] * df[f's_het_post_f{i}']\n",
    "        df[f'weighted_s_het_b{i}'] = df[f'inv_dist_b{i}'] * df[f's_het_post_b{i}']\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "weighted_f_b_final = compute_weighted_s_het(filtered_f_b_final, num_merges=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50610429",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_f_b_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b418cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_f_b_final[['inv_dist_f1', 'inv_dist_f2', 'inv_dist_f3', \n",
    "                          'inv_dist_b1', 'inv_dist_b2', 'inv_dist_b3']].agg(['min', 'max', 'mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12054123",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_f_b_final[weighted_f_b_final['inv_dist_f1'] == float('inf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53dee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_b_final_merged_s_het[f_b_final_merged_s_het['variant'] == '20:627259:T:C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to keep only the weighted s_het values from the dataframe\n",
    "def keep_weighted_s_het(df, num_merges=3):\n",
    "    # List to store column names for weighted s_het values\n",
    "    columns_to_keep = ['variant', 'chr', 'pos']\n",
    "\n",
    "    # Loop to collect the weighted_s_het column names for forward and backward directions\n",
    "    for i in range(1, num_merges + 1):\n",
    "        columns_to_keep.append(f'weighted_s_het_f{i}')\n",
    "        columns_to_keep.append(f'weighted_s_het_b{i}')\n",
    "\n",
    "    # Keep only the relevant columns\n",
    "    df_filtered = df[columns_to_keep]\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "# Example usage:\n",
    "weighted_s_het_only = keep_weighted_s_het(weighted_f_b_final, num_merges=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_s_het_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25bf174",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_s_het_only[['weighted_s_het_f1', 'weighted_s_het_b1', 'weighted_s_het_f2', \n",
    "                          'weighted_s_het_b2', 'weighted_s_het_f3', 'weighted_s_het_b3']].agg(['min', 'max', 'mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7e72cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
